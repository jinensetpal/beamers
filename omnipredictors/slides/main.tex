\documentclass{beamer}
\usepackage[utf8]{inputenc}
\usepackage{listings}
\usepackage{booktabs}
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{bm}
\usepackage{enumitem}
\usepackage{hyperref}
\usepackage[export]{adjustbox}
\usepackage{svg}

\usetheme{Madrid}
\definecolor{mlpblue}{rgb}{0.1, 0.14, 0.24}

\useoutertheme{infolines} % Alternatively: miniframes, infolines, split
\useinnertheme{circles}
\usecolortheme[named=mlpblue]{structure}

\lstset{basicstyle=\footnotesize\ttfamily,breaklines=true}

%------------------------------------------------------------
%This block of code defines the information to appear in the
%Title page
\title[Omnipredictors]{\href{https://arxiv.org/abs/2109.05389}{Omnipredictors}\thanks{Gopalan, Kalai, Reingold, Sharan, Wieder}: One Predictor to Rule Them All}

\subtitle{Heavily adapted from \href{https://youtu.be/DCPRdL03-dk}{P.~Gopalan's Talk} at IAS}

\author[Machine Learning @ Purdue] % optional
{J.~Setpal} 

\date{April 18, 2024}

\titlegraphic{\includegraphics[width=7cm]{../../shared/logo-long.pdf}}

%End of title page configuration block
%------------------------------------------------------------

%The next block of commands puts the table of contents at the 
%beginning of each section and highlights the current section:

\AtBeginSection[]
{
  \begin{frame}
    \frametitle{Outline}
    \tableofcontents[currentsection]
  \end{frame}
}
% ------------------------------------------------------------


\begin{document}

\frame{\titlepage}


%---------------------------------------------------------
% This block of code is for the table of contents after
% the title page
% \begin{frame}
% \frametitle{Outline}
% \tableofcontents
% \end{frame}
%---------------------------------------------------------

\begin{frame}{Supervised Learning Synopsis}
	We'll start with an \textit{overview} of supervised learning paradigm:
	\begin{enumerate}[label=\arabic*.]
		\item Dataset $\mathcal{D} := \{(x_i, y_i)\}^N_{i=1};~N \ll \infty;~\mathcal{D} \sim $ ``Real World'' \pause
		\item Parameterized model $f_{\bm{\theta}} : \mathcal{X} \rightarrow \mathcal{Y}$ \pause
		\item Objective: Train $\bm{\theta}$ s.t. $f_{\bm{\theta}}(x) = \hat{y} \approx y$ \pause
	\end{enumerate}
	How do we mathematically encode $\hat{y} \approx y$? \pause A loss (distance) function!
	\begin{enumerate}[label=\arabic*.]
			\setcounter{enumi}{3}
		\item Loss function $L : \mathcal{Y} \times \mathcal{Y} \rightarrow \mathbb{R};~L(\hat{y}, y) \approx 0~\text{iff}~\hat{y} \approx y; L$ is continuous. \pause
	\end{enumerate}
	How can we update our weights to optimize against this loss function? \pause
	\begin{enumerate}[label=\arabic*.]
			\setcounter{enumi}{4}
		\item Gradient Descent! $\bm{\theta} = \bm{\theta} + \alpha \cdot \frac{\partial L}{\partial \bm{\theta}}$
	\end{enumerate}
	Iterate (5) until convergence. \pause \newline \\
	$L$ is minimized over $\mathcal{D}$, not over the real world. \pause This is \textbf{empirical risk}:
	\begin{gather}
		\min_{\bm{\theta}} \frac{1}{N}\sum^N_{i=1} L(f_{\bm{\theta}}(x_i), y_i)
	\end{gather}
\end{frame}

\begin{frame}{Generalization Error}
	We also split $\mathcal{D}$ into training, validation, test splits to minimize overfitting. \pause \newline \\
	Usually $L_{valid} \not\approx L_{train}$ after training. That's our generalization gap.
	\begin{center}
		\includegraphics[width=.8\textwidth]{img/generalization}
	\end{center}
\end{frame}

\begin{frame}{Challenge Statement}
	\textbf{Problem:} Different loss functions typically have divergent geometries. \pause \newline \\

	This means gradient descent obtains a \textbf{different\footnote{usually, local} optima} for two such functions, despite \underline{sharing minima} for $\bm{\theta}$ s.t. $\hat{y} \approx y$. \pause \newline \\

	Let's evaluate this empirically on $\ell_1$ and $\ell_2$ losses, which optimize for median and mean respectively:
	\begin{gather}
		\ell_1 = |y-\hat{y}|,~\ell_2 = (y-\hat{y})^2 \\ 
		x \sim f(\epsilon \sim \mathcal{U}[0,1]) := \begin{cases}
			0 & \epsilon \leq 0.4 \\
			\mathcal{U}[0.8, 1] & \text{otherwise}
		\end{cases}
	\end{gather} \pause
	\textbf{Omnipredictors} provides a framework for rigorous guarantees, deriving $\tilde{p} \approx p^*$: a predictor that is able to \textit{simultaneously minimize} a family of \underline{convex loss functions}.
\end{frame}

\begin{frame}{Multigroup Fairness}
	We can split $\mathcal{D}$ into various \textit{subgroups} based on \textbf{shared characteristics}. These can be explicit or implicit (i.e. subgroups we don't know of):
	\begin{table}[t]
		\begin{center}
			\begin{tabular}{lcccc}
				\toprule
				& \bf Group-1 & \bf Group-2 & \bf Group-3 & \bf Group-4 \\
				\midrule
				\bf Accuracy & 0.9593 & 0.6249 & 0.3157 & 0.2664 \\
				\bf Loss & 0.0021 & 0.4102 & 1.3457 & 1.7664 \\
				\bf Proportion & 0.9 & 0.08 & 0.0075 & 0.0025 \\
				\bottomrule
			\end{tabular}
		\end{center}
	\end{table} \pause
	Empirical Risk is \textit{only} $0.0492$, but inference is unreliable for subgroups 2-4. \pause \newline \\

	One notion of fairness stipulates equal risk for every subgroup. However, finding subgroups is hard for \underline{high-dimensional data}.
\end{frame}

\begin{frame}{Multiaccuracy \& Multigroup Fairness}
	\begin{columns}
		\begin{column}{0.3\textwidth}
			\begin{center}
				\includegraphics[width=.8\textwidth]{img/partitions}
			\end{center}
		\end{column} \pause
		\begin{column}{0.7\textwidth}
			Let $C$ be the collection of subsets. We probe it further for correlations. \pause \newline \\

			$\tilde{p}$ is $(C, \alpha)$-multiaccurate if:
			\begin{gather}
				\max_{c \in C} |\mathbb{E}[c(x)(y-\tilde{p}(x))]| \leq \alpha
			\end{gather} \pause
			$\tilde{p}$ is $(C, \alpha)$-multicalibrated if:
			\begin{gather}
				\max_{c \in C} E[|\mathbb{E}[c(x)(y-\tilde{p}(x))]|] \leq \alpha
			\end{gather} \pause
			If we can find correlation with the error, there's some advantage to be gained. We minimize this to train a \textbf{weak agnostic learner}.
		\end{column}
	\end{columns}
\end{frame}

\begin{frame}{Omnipredictors}
	If we know $p^*$, it is easy for us take take the optimal action. \pause \newline \\

	For $y \in \{0, 1\},~y \sim \text{Bernoulli}(p^*)$. We denote optimal action $t := k_\ell^* \circ p^*$\pause \newline \\

	This paper connects multigroup fairness with the notion of a weak agnostic learner, to formulate $(L, C)$-omnipredictors. \pause Specifically, it trains $g_{\bm{\theta}} \approx p^*$. \pause \newline \\

	\textbf{Intuitively}: the idea is to \textit{extract the predictive power} of the data. \pause \newline \\

	Let $L_{cvx}$ be a set of Lipschitz, convex, bounded losses. \pause If $f_{\bm{\theta}}$ is $C$-multicalibrated with some error $\alpha$, it is an $(L_{cvx}, C, \alpha)$-omnipredictor. \pause \newline \\

	Multicalibration implies omniprediction for all convex loss functions.
\end{frame}

\begin{frame}{Training Agnostic Predictors}
	We can use this framework to train a predictor s.t. a new model trained just on \underline{one loss function} performs equivalently to the omnipredictor.
	\begin{gather}
		C = \{c: \mathcal{X} \rightarrow \mathcal{Y}\} \\
		w: (0,1] \rightarrow (0, 1]~s.t.~w(\alpha) \leq \alpha
	\end{gather} \pause
	We then train with the following objective:
	\begin{gather}
		\min_{\bm{\theta}} \textbf{Cov}_{\mathcal{D}}[c(x), y]
	\end{gather}
	Then, with probability $1-\delta$ the weak learner returns $c$ s.t. $\textbf{Cov}_{\mathcal{D}}[c(x), y] \geq w(\alpha)$. \pause \newline \\

	We use this to compute an $\alpha$-multicalibrated partition by a layered branching program that runs in $\mathcal{O}(\frac{l}{w(\alpha/2)})^{\mathcal{O}(l)}$.
\end{frame}

\begin{frame}{Thank you!}
	\begin{center}
		Have an awesome rest of your day!
	\end{center}
	\begin{center}
		\textbf{Slides:} {\small \url{https://cs.purdue.edu/homes/jsetpal/slides/omnipredictors.pdf}}
	\end{center}
\end{frame}

\end{document}
